MergeArgs(model_name='coma_fc', agent_num=3, hid_size=64, obs_size=18, continuous=False, action_dim=5, init_std=0.1, policy_lrate=0.01, value_lrate=0.01, max_steps=200, batch_size=1024, gamma=0.9, normalize_advantages=False, entr=0.01, entr_inc=0.0, action_num=5, q_func=True, train_episodes_num=100000, replay=True, replay_buffer_size=1000000.0, replay_warmup=0, cuda=True, grad_clip=True, save_model_freq=1000, target=True, target_lr=0.1, behaviour_update_freq=100, critic_update_times=10, target_update_freq=100, gumbel_softmax=False, epsilon_softmax=False, online=True, reward_record_type='episode_mean_step', shared_parameters=True)

Episode: 1000, Mean Reward: -4.3771, Action Loss: 0.0163, Value Loss is: 1.8735, Entropy: 1647.8253

The model is saved!

Episode: 2000, Mean Reward: -3.3937, Action Loss: 0.0357, Value Loss is: 1.8675, Entropy: 1647.7927

The model is saved!

Episode: 3000, Mean Reward: -4.1152, Action Loss: -0.0368, Value Loss is: 1.6127, Entropy: 1647.1041

The model is saved!

Episode: 4000, Mean Reward: -2.9839, Action Loss: -0.0545, Value Loss is: 1.2191, Entropy: 1645.2275

The model is saved!

Episode: 5000, Mean Reward: -3.6372, Action Loss: -0.0342, Value Loss is: 1.5130, Entropy: 1647.1450

The model is saved!

Episode: 6000, Mean Reward: -3.9797, Action Loss: -0.0009, Value Loss is: 1.1493, Entropy: 1647.3307

The model is saved!

Episode: 7000, Mean Reward: -4.3565, Action Loss: -0.0286, Value Loss is: 1.3581, Entropy: 1646.9630

The model is saved!

Episode: 8000, Mean Reward: -3.8547, Action Loss: 0.0141, Value Loss is: 1.0473, Entropy: 1647.5199

The model is saved!

Episode: 9000, Mean Reward: -3.8447, Action Loss: -0.0086, Value Loss is: 1.2593, Entropy: 1647.3269

The model is saved!

Episode: 10000, Mean Reward: -3.0569, Action Loss: -0.0225, Value Loss is: 1.4207, Entropy: 1647.3351

The model is saved!

Episode: 11000, Mean Reward: -3.8739, Action Loss: 0.0061, Value Loss is: 2.3993, Entropy: 1647.6757

The model is saved!

Episode: 12000, Mean Reward: -3.6980, Action Loss: -0.0369, Value Loss is: 1.7241, Entropy: 1647.3146

The model is saved!

Episode: 13000, Mean Reward: -5.7262, Action Loss: 0.0179, Value Loss is: 1.2929, Entropy: 1647.2694

The model is saved!

Episode: 14000, Mean Reward: -2.7616, Action Loss: 0.0106, Value Loss is: 1.2753, Entropy: 1647.2592

The model is saved!

Episode: 15000, Mean Reward: -3.3458, Action Loss: -0.0242, Value Loss is: 1.0211, Entropy: 1646.7283

The model is saved!

Episode: 16000, Mean Reward: -3.2558, Action Loss: -0.0154, Value Loss is: 1.1246, Entropy: 1646.9392

The model is saved!

Episode: 17000, Mean Reward: -4.1374, Action Loss: -0.0240, Value Loss is: 1.1050, Entropy: 1647.2836

The model is saved!

Episode: 18000, Mean Reward: -5.1958, Action Loss: -0.0212, Value Loss is: 1.1277, Entropy: 1647.2767

The model is saved!

Episode: 19000, Mean Reward: -3.4284, Action Loss: -0.0150, Value Loss is: 0.8573, Entropy: 1647.2798

The model is saved!

Episode: 20000, Mean Reward: -3.0881, Action Loss: 0.0077, Value Loss is: 1.2984, Entropy: 1647.1965

The model is saved!

Episode: 21000, Mean Reward: -4.2294, Action Loss: -0.0021, Value Loss is: 1.4110, Entropy: 1647.3918

The model is saved!

Episode: 22000, Mean Reward: -4.7563, Action Loss: -0.0016, Value Loss is: 1.3979, Entropy: 1647.0170

The model is saved!

Episode: 23000, Mean Reward: -3.2721, Action Loss: -0.0198, Value Loss is: 1.3994, Entropy: 1647.2869

The model is saved!

Episode: 24000, Mean Reward: -3.1199, Action Loss: -0.0321, Value Loss is: 1.3298, Entropy: 1646.8281

The model is saved!

Episode: 25000, Mean Reward: -4.7060, Action Loss: -0.0022, Value Loss is: 1.7273, Entropy: 1647.6575

The model is saved!

Episode: 26000, Mean Reward: -4.2909, Action Loss: -0.0322, Value Loss is: 1.3687, Entropy: 1647.2781

The model is saved!

Episode: 27000, Mean Reward: -2.8668, Action Loss: 0.0061, Value Loss is: 1.4195, Entropy: 1647.4028

The model is saved!

Episode: 28000, Mean Reward: -3.6823, Action Loss: -0.0219, Value Loss is: 1.1150, Entropy: 1647.3638

The model is saved!

Episode: 29000, Mean Reward: -4.3252, Action Loss: 0.0164, Value Loss is: 1.6370, Entropy: 1647.2225

The model is saved!

Episode: 30000, Mean Reward: -4.2399, Action Loss: -0.0184, Value Loss is: 1.4642, Entropy: 1647.3276

The model is saved!

Episode: 31000, Mean Reward: -3.1275, Action Loss: 0.0174, Value Loss is: 1.2481, Entropy: 1647.4570

The model is saved!

